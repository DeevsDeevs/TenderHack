{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa34d6e5-acf0-42ee-908b-66d5d0a5ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6e415b04-2c98-4e9d-92c4-d4c3e136cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from simpletransformers.language_modeling import (\n",
    "    LanguageModelingModel,\n",
    "    LanguageModelingArgs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "544570e4-ed1f-4e2f-bb1c-c02411d5ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fc189b3-d1da-471f-a957-136ad55e728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "07c683f7-3e04-4992-87c9-5a8014366122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    return f\"GPU memory occupied: {info.used//1024**2} MB.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "79648ea2-7b71-442f-869f-c3aeecee3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "46f05f7c-be0b-4605-99ce-65dfc8400cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    model: torch.nn.Module\n",
    "    \n",
    "    Используется для подробного вывода\n",
    "    параметров модели\n",
    "    \"\"\"\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            print(name, parameter.numel())\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0fec1cf0-6347-4671-8eee-11dbd65908c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"data/goods.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "47d0ad0e-abef-4d83-91a5-9bca1deed7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization_characteristics(characteristics: str):\n",
    "    if characteristics is None:\n",
    "        return \"\"\n",
    "    characteristics = ast.literal_eval(characteristics.lower())\n",
    "    data = []\n",
    "    for characteristic in characteristics:\n",
    "        if \"value\" in characteristic:\n",
    "            if len(characteristic[\"value\"].split()) <= 3:\n",
    "                if (\"value\" in characteristic) and (\"unit\" in characteristic):\n",
    "                    data.append(f\"{characteristic['value']} {characteristic['unit']}\")\n",
    "                elif characteristic[\"value\"] in [\"да\", \"нет\"]:\n",
    "                    if len(characteristic[\"name\"].split()) <= 3:\n",
    "                        data.append(characteristic['name'])\n",
    "                else:\n",
    "                    data.append(characteristic[\"value\"])\n",
    "    return \", \".join(list({i.strip() for i in data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a274bf1a-9ead-4d90-9cc8-8ec360905a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[[126302, 170141]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "047d15f1-c2a0-4fc8-8e09-a83969bb9fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 356573/356573 [00:37<00:00, 9535.18it/s] \n"
     ]
    }
   ],
   "source": [
    "df['Характеристики'] = df['Характеристики'].progress_apply(lambda s: standardization_characteristics(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "94707f4e-cbbc-4982-842e-c255c7da75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"Название СТЕ\"].str.lower().str.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b595d32c-f938-4691-8797-ad72bed609ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cat_count\"] = df.groupby('Категория')['Категория'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a0e6a7ab-6706-43a9-b7ab-6e50b71ac4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"cat_count\"] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b2eaa654-5621-4504-b9bd-77e1c3c76765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Расходные материалы и комплектующие для лазерных принтеров и МФУ                                  9266\n",
       "Учебники печатные общеобразовательного назначения                                                 6912\n",
       "Одежда специальная для защиты от общих производственных загрязнений и механических воздействий    3510\n",
       "Предметы внутреннего интерьера                                                                    2456\n",
       "Фурнитура для сантехнического оборудования                                                        2046\n",
       "                                                                                                  ... \n",
       "Наборы для катетеризации центральных вен по \"сельдингеру\"                                            3\n",
       "Натрий тетраборнокислый 10-водный (реактив)                                                          3\n",
       "Техническое обслуживание и содержание объектов наружного освещения                                   3\n",
       "Битум строительный                                                                                   3\n",
       "Расходные материалы для аппарата \"cell saver                                                         3\n",
       "Name: Категория, Length: 4314, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Категория\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "81fe0db2-b8d9-4016-bdab-1c36526f52fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df[\"Target\"] = le.fit_transform(df[\"Категория\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f2b58f2e-65b5-4daa-821a-54dcfcaa2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df[[\"text\", \"Target\"]].values,\n",
    "                                   test_size=0.1,\n",
    "                                   random_state=42,\n",
    "                                   stratify=df[\"Target\"],\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b6870508-f328-4766-b789-e0efe02e9478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318585, 2)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0766d174-022a-44c2-ab3e-7d3af842826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35399, 2)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5b139d72-77d7-4611-b2d2-f856d74e5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(X_train[:,0]).to_csv(\"data/train.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "96e9da39-6dde-4a5b-9e8c-5eeaf3683b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(X_test[:,0]).to_csv(\"data/test.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ba801-4a6c-4074-9473-28bde265b278",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/LaBSE-en-ru were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ee13f83efa4c2e9f4888464ab8058d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/318589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f56b1c7e9bd4b07b914e12531b51d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/bert_cached_lm_198_train.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33736ec8931a41c5bd2531360f9bc131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4766327aa248829410016b5223963d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/3748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/user/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0612f2c93a9e4f66b8a52fe4069bfba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/3748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model_args = LanguageModelingArgs()\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.num_train_epochs = 3\n",
    "model_args.max_seq_length = 200\n",
    "model_args.dataset_type = \"simple\"\n",
    "model_args.batch_size = 32\n",
    "\n",
    "train_file = \"data/train.txt\"\n",
    "test_file = \"data/test.txt\"\n",
    "\n",
    "model = LanguageModelingModel(\n",
    "    \"bert\", \"cointegrated/LaBSE-en-ru\", args=model_args\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_file, eval_file=test_file)\n",
    "\n",
    "# Evaluate the model\n",
    "result = model.eval_model(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1ea38722-69ff-45dc-919e-b30c009ff5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.3518733615212017, 'perplexity': tensor(10.5052)}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1a09a-28b9-4870-a1d9-4c0b09192c84",
   "metadata": {},
   "source": [
    "#### Test MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "97b0025e-e71c-4759-a91e-76ac1d219156",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6e725875-673d-45e3-b940-64c9f0228ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModelingModel(\n",
    "    \"bert\", MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "434526dc-d326-4f7d-b2f0-ebca749cfaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3463304340839386,\n",
       "  'token': 22933,\n",
       "  'token_str': 'мяч',\n",
       "  'sequence': 'Хочу купить волебольный мяч'},\n",
       " {'score': 0.15694421529769897,\n",
       "  'token': 12778,\n",
       "  'token_str': 'набор',\n",
       "  'sequence': 'Хочу купить волебольный набор'},\n",
       " {'score': 0.020530350506305695,\n",
       "  'token': 15021,\n",
       "  'token_str': 'комплект',\n",
       "  'sequence': 'Хочу купить волебольный комплект'},\n",
       " {'score': 0.01725109852850437,\n",
       "  'token': 7764,\n",
       "  'token_str': 'знак',\n",
       "  'sequence': 'Хочу купить волебольный знак'},\n",
       " {'score': 0.015098798088729382,\n",
       "  'token': 42450,\n",
       "  'token_str': 'теннис',\n",
       "  'sequence': 'Хочу купить волебольный теннис'}]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model=MODEL_NAME, framework=\"pt\")\n",
    "unmasker(\"Хочу купить волебольный [MASK]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
