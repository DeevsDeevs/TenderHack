{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/exp_fold_training/temp\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 22 23:23:40 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100 Graphics D...  On   | 00000000:B7:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    66W / 400W |      0MiB / 81252MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --fuzzy --folder https://drive.google.com/drive/folders/1XwjWRA6fcqfiTuxHhr88KoSjKISyI4sp?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.contrib.telegram import tqdm as tgdm_tg\n",
    "from prettytable import PrettyTable\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, matthews_corrcoef\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /home/jovyan/nltk_data/tokenizers/punkt/PY3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mv /home/jovyan/nltk_data/tokenizers/punkt/PY3/russian.pickle /home/jovyan/nltk_data/tokenizers/punkt/PY3/ru.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import nltk\n",
    "from string import punctuation\n",
    "\n",
    "# nltk.download('punkt', download_dir=\"/home/jovyan/nltk_data\")\n",
    "\n",
    "punctuation = set(punctuation)\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    tokens = nltk.word_tokenize(text, language=\"ru\")\n",
    "    tokens = [morph.parse(i)[0].normal_form for i in tokens if i not in punctuation]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    return f\"GPU memory occupied: {info.used//1024**2} MB.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    model: torch.nn.Module\n",
    "    \n",
    "    Используется для подробного вывода\n",
    "    параметров модели\n",
    "    \"\"\"\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            print(name, parameter.numel())\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/LaBSE-en-ru were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/LaBSE-en-ru\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/LaBSE-en-ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "contracts = pd.read_feather(\"contracts.feather\")\n",
    "goods = pd.read_feather(\"goods.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods[\"Название_СТЕ_source\"] = goods[\"Название СТЕ\"]\n",
    "goods[\"Название СТЕ\"] = goods[\"Название СТЕ\"].str.lower().str.strip().progress_apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods[\"Название СТЕ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods.to_feather(\"goods_2.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization_characteristics(characteristics: str):\n",
    "    try:\n",
    "        characteristics = eval(characteristics.lower())\n",
    "        data = []\n",
    "        for characteristic in characteristics:\n",
    "            if \"value\" in characteristic:\n",
    "                if len(characteristic[\"value\"].split()) <= 3:\n",
    "                    if (\"value\" in characteristic) and (\"unit\" in characteristic):\n",
    "                        data.append(f\"{characteristic['value']} {characteristic['unit']}\")\n",
    "                    elif characteristic[\"value\"] in [\"да\", \"нет\"]:\n",
    "                        if len(characteristic[\"name\"].split()) <= 3:\n",
    "                            data.append(characteristic['name'])\n",
    "                    else:\n",
    "                        data.append(characteristic[\"value\"])\n",
    "        data = [clear_text(i.strip()) for i in data]\n",
    "        data = sorted(set(data))\n",
    "        return \", \".join(data)\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods[\"Характеристики_source\"] = goods[\"Характеристики\"]\n",
    "goods[\"Характеристики\"] = goods[\"Характеристики\"].progress_apply(standardization_characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods.to_feather(\"goods_3.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = goods.drop_duplicates(subset=[\"Название СТЕ\", \"Код КПГЗ\", \"Характеристики\"])\n",
    "count_df = goods[[\"Название СТЕ\", \"Код КПГЗ\", \"Характеристики\"]].drop_duplicates().groupby(\"Код КПГЗ\").agg(\"count\").reset_index()\n",
    "classes = count_df.loc[count_df[\"Название СТЕ\"] >= 1, \"Код КПГЗ\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5307"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertCLS(nn.Module):\n",
    "    def __init__(self, model, n_classes):\n",
    "        super(BertCLS, self).__init__()\n",
    "        self.model = model\n",
    "        self.fc = nn.Linear(768, n_classes)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return self.fc(self.model(**batch).pooler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls = BertCLS(model, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected2 = selected[selected[\"Код КПГЗ\"].isin(classes)].reset_index(drop=True)\n",
    "selected2[\"Характеристики\"] = selected2[\"Характеристики\"].replace(np.nan, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "01.13.13.01.01          9260\n",
       "01.14.01.01             6906\n",
       "01.11.03.01.01.99       4646\n",
       "01.09.08.01.99          3885\n",
       "01.11.02.02.99          3828\n",
       "                        ... \n",
       "01.01.10.03.03             1\n",
       "01.02.10.02.01.01          1\n",
       "01.02.10.09.02.25.01       1\n",
       "01.26.02.04.02.01          1\n",
       "01.02.10.37.01.01.04       1\n",
       "Name: Код КПГЗ, Length: 5307, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected2[\"Код КПГЗ\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID СТЕ</th>\n",
       "      <th>Название СТЕ</th>\n",
       "      <th>Категория</th>\n",
       "      <th>Код КПГЗ</th>\n",
       "      <th>Характеристики</th>\n",
       "      <th>Название_СТЕ_source</th>\n",
       "      <th>Характеристики_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1153097</td>\n",
       "      <td>мяч футбольный mikasa regateador5-g</td>\n",
       "      <td>Мячи футбольные</td>\n",
       "      <td>01.08.01.13.01</td>\n",
       "      <td>5 усл. ед, mikasa, regateador5-r, белый, любит...</td>\n",
       "      <td>мяч футбольный MIKASA REGATEADOR5-G</td>\n",
       "      <td>[{\"Name\":\"Модель\",\"Id\":283795036,\"Value\":\"REGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1153130</td>\n",
       "      <td>мяч волейбольный gala pro-line 10 fivb</td>\n",
       "      <td>Мячи волейбольные</td>\n",
       "      <td>01.08.01.14.03.01</td>\n",
       "      <td>5, gala, pro-line 10 fivb, белый, профессионал...</td>\n",
       "      <td>мяч волейбольный Gala Pro-Line 10 FIVB</td>\n",
       "      <td>[{\"Name\":\"Марка\",\"Id\":284249992,\"Value\":\"Gala\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1153163</td>\n",
       "      <td>мяч волейбольный mikasa mva380k-obl</td>\n",
       "      <td>Мячи волейбольные</td>\n",
       "      <td>01.08.01.14.03.01</td>\n",
       "      <td>5, mikasa, mva380k, оранжевый, синт, тренровочный</td>\n",
       "      <td>мяч волейбольный Mikasa MVA380K-OBL</td>\n",
       "      <td>[{\"Name\":\"Марка\",\"Id\":284249802,\"Value\":\"MIKAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1153174</td>\n",
       "      <td>мяч волейбольный wilson super soft play</td>\n",
       "      <td>Мячи волейбольные</td>\n",
       "      <td>01.08.01.14.03.01</td>\n",
       "      <td>5, super soft play, wilson, белый, любительски...</td>\n",
       "      <td>мяч волейбольный Wilson Super Soft Play</td>\n",
       "      <td>[{\"Name\":\"Марка\",\"Id\":284246959,\"Value\":\"WILSO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1159300</td>\n",
       "      <td>gutrend комплект расходный материал для fun 11...</td>\n",
       "      <td>Расходные материалы, комплектующие для прочего...</td>\n",
       "      <td>01.20.10.99</td>\n",
       "      <td>120 г, 170 мм, 220 мм, 50 мм, 6 шт, hepa фильт...</td>\n",
       "      <td>Gutrend комплект расходных материалов для FUN ...</td>\n",
       "      <td>[{\"Name\":\"Тип\",\"Id\":284280400,\"Value\":\"Расходн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354225</th>\n",
       "      <td>35228990</td>\n",
       "      <td>шина 23x10.50-12 107a8 starco as loader tl</td>\n",
       "      <td>Шины для грузовых автомобилей и спецтехники, п...</td>\n",
       "      <td>01.09.08.10.05.02</td>\n",
       "      <td>10 кг, 12 дюйм, 580 мм, 8 pr, starco, бескамер...</td>\n",
       "      <td>Шина 23x10.50-12 107A8 Starco AS LOADER TL</td>\n",
       "      <td>[{\"Name\":\"Бескамерные\",\"Id\":369460372,\"Value\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354226</th>\n",
       "      <td>35229086</td>\n",
       "      <td>кнопка включение рабочий освещение для минипог...</td>\n",
       "      <td>Запчасти к погрузчикам</td>\n",
       "      <td>01.09.08.03</td>\n",
       "      <td>12 в, 650, 90 г, avant, включение рабочий осве...</td>\n",
       "      <td>Кнопка включения рабочего освещения для минипо...</td>\n",
       "      <td>[{\"Name\":\"Артикул запчасти\",\"Id\":369463362,\"Va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354227</th>\n",
       "      <td>35231655</td>\n",
       "      <td>обои флизелиновый под покраска nc antivandal а...</td>\n",
       "      <td>Обои</td>\n",
       "      <td>01.11.03.11.08</td>\n",
       "      <td>106 смотреть, 25 м, 350 г, 4 шт, 4010-16, anti...</td>\n",
       "      <td>Обои флизелиновые под покраску NC Antivandal, ...</td>\n",
       "      <td>[{\"Name\":\"Описание\",\"Id\":369399594,\"Value\":\"со...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354228</th>\n",
       "      <td>35231695</td>\n",
       "      <td>мусорный ведро kimberly-clark aquarius белый п...</td>\n",
       "      <td>Контейнеры и другие емкости для мусора пластма...</td>\n",
       "      <td>01.20.03.03.06</td>\n",
       "      <td>2 шт, 29.00000 смотреть, 4,76 кг, 43.00000 смо...</td>\n",
       "      <td>Мусорное ведро Kimberly-Clark Aquarius белое п...</td>\n",
       "      <td>[{\"Name\":\"Вид емкости\",\"Id\":369380812,\"Value\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354229</th>\n",
       "      <td>35231999</td>\n",
       "      <td>весы cas db-ii 150 быть</td>\n",
       "      <td>Весы</td>\n",
       "      <td>01.20.99.01.05.02</td>\n",
       "      <td>150 кг, 220 в, 360 460 мм, весы, наличие аккум...</td>\n",
       "      <td>ВЕСЫ CAS DB-II 150 (Е)</td>\n",
       "      <td>[{\"Name\":\"Класс точности\",\"Id\":369436663,\"Valu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354230 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID СТЕ                                       Название СТЕ  \\\n",
       "0        1153097                мяч футбольный mikasa regateador5-g   \n",
       "1        1153130             мяч волейбольный gala pro-line 10 fivb   \n",
       "2        1153163                мяч волейбольный mikasa mva380k-obl   \n",
       "3        1153174            мяч волейбольный wilson super soft play   \n",
       "4        1159300  gutrend комплект расходный материал для fun 11...   \n",
       "...          ...                                                ...   \n",
       "354225  35228990         шина 23x10.50-12 107a8 starco as loader tl   \n",
       "354226  35229086  кнопка включение рабочий освещение для минипог...   \n",
       "354227  35231655  обои флизелиновый под покраска nc antivandal а...   \n",
       "354228  35231695  мусорный ведро kimberly-clark aquarius белый п...   \n",
       "354229  35231999                            весы cas db-ii 150 быть   \n",
       "\n",
       "                                                Категория           Код КПГЗ  \\\n",
       "0                                         Мячи футбольные     01.08.01.13.01   \n",
       "1                                      Мячи волейбольные   01.08.01.14.03.01   \n",
       "2                                      Мячи волейбольные   01.08.01.14.03.01   \n",
       "3                                      Мячи волейбольные   01.08.01.14.03.01   \n",
       "4       Расходные материалы, комплектующие для прочего...        01.20.10.99   \n",
       "...                                                   ...                ...   \n",
       "354225  Шины для грузовых автомобилей и спецтехники, п...  01.09.08.10.05.02   \n",
       "354226                             Запчасти к погрузчикам        01.09.08.03   \n",
       "354227                                               Обои     01.11.03.11.08   \n",
       "354228  Контейнеры и другие емкости для мусора пластма...     01.20.03.03.06   \n",
       "354229                                               Весы  01.20.99.01.05.02   \n",
       "\n",
       "                                           Характеристики  \\\n",
       "0       5 усл. ед, mikasa, regateador5-r, белый, любит...   \n",
       "1       5, gala, pro-line 10 fivb, белый, профессионал...   \n",
       "2       5, mikasa, mva380k, оранжевый, синт, тренровочный   \n",
       "3       5, super soft play, wilson, белый, любительски...   \n",
       "4       120 г, 170 мм, 220 мм, 50 мм, 6 шт, hepa фильт...   \n",
       "...                                                   ...   \n",
       "354225  10 кг, 12 дюйм, 580 мм, 8 pr, starco, бескамер...   \n",
       "354226  12 в, 650, 90 г, avant, включение рабочий осве...   \n",
       "354227  106 смотреть, 25 м, 350 г, 4 шт, 4010-16, anti...   \n",
       "354228  2 шт, 29.00000 смотреть, 4,76 кг, 43.00000 смо...   \n",
       "354229  150 кг, 220 в, 360 460 мм, весы, наличие аккум...   \n",
       "\n",
       "                                      Название_СТЕ_source  \\\n",
       "0                     мяч футбольный MIKASA REGATEADOR5-G   \n",
       "1                  мяч волейбольный Gala Pro-Line 10 FIVB   \n",
       "2                     мяч волейбольный Mikasa MVA380K-OBL   \n",
       "3                 мяч волейбольный Wilson Super Soft Play   \n",
       "4       Gutrend комплект расходных материалов для FUN ...   \n",
       "...                                                   ...   \n",
       "354225         Шина 23x10.50-12 107A8 Starco AS LOADER TL   \n",
       "354226  Кнопка включения рабочего освещения для минипо...   \n",
       "354227  Обои флизелиновые под покраску NC Antivandal, ...   \n",
       "354228  Мусорное ведро Kimberly-Clark Aquarius белое п...   \n",
       "354229                             ВЕСЫ CAS DB-II 150 (Е)   \n",
       "\n",
       "                                    Характеристики_source  \n",
       "0       [{\"Name\":\"Модель\",\"Id\":283795036,\"Value\":\"REGA...  \n",
       "1       [{\"Name\":\"Марка\",\"Id\":284249992,\"Value\":\"Gala\"...  \n",
       "2       [{\"Name\":\"Марка\",\"Id\":284249802,\"Value\":\"MIKAS...  \n",
       "3       [{\"Name\":\"Марка\",\"Id\":284246959,\"Value\":\"WILSO...  \n",
       "4       [{\"Name\":\"Тип\",\"Id\":284280400,\"Value\":\"Расходн...  \n",
       "...                                                   ...  \n",
       "354225  [{\"Name\":\"Бескамерные\",\"Id\":369460372,\"Value\":...  \n",
       "354226  [{\"Name\":\"Артикул запчасти\",\"Id\":369463362,\"Va...  \n",
       "354227  [{\"Name\":\"Описание\",\"Id\":369399594,\"Value\":\"со...  \n",
       "354228  [{\"Name\":\"Вид емкости\",\"Id\":369380812,\"Value\":...  \n",
       "354229  [{\"Name\":\"Класс точности\",\"Id\":369436663,\"Valu...  \n",
       "\n",
       "[354230 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "selected2[\"target\"] = le.fit_transform(selected2[\"Код КПГЗ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(selected2[[\"Название СТЕ\", \"target\"]].values,\n",
    "                                   test_size=0.01,\n",
    "                                   random_state=42,\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3543, 350687)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = X_train[:10000], X_test[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.34803940942326"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected2[\"Название СТЕ\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, target = self.data[idx]\n",
    "        return text, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    model_input = []\n",
    "    model_target = []\n",
    "    for text, target in batch:\n",
    "        model_input.append(text)\n",
    "        model_target.append(target)\n",
    "\n",
    "    tok = tokenizer(model_input, padding=True,\n",
    "                    max_length=200, truncation=True,\n",
    "                    return_tensors='pt')\n",
    "    return tok, torch.tensor(model_target).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(dataset, shuffle, batch_size):\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=False,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "train_dataset = ClassificationDataset(X_train)\n",
    "train_loader = get_loader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_dataset = ClassificationDataset(X_test)\n",
    "test_loader = get_loader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "bert_cls = bert_cls.to(device)\n",
    "\n",
    "num_epochs = 5\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "total_steps = (len(train_loader) * num_epochs)\n",
    "optimizer = optim.AdamW(bert_cls.parameters(), lr=2e-4)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=2e-4,\n",
    "                                          total_steps=total_steps,\n",
    "                                          div_factor=25,\n",
    "                                          pct_start=0.1)\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, device, train_loader, optimizer, epoch, gradient_accumulation_steps, scheduler):\n",
    "    model.train()\n",
    "    train_loader_length = len(train_loader) - 1 # хотим знать когда эпоха закончится\n",
    "    pbar = tgdm_tg(train_loader, token=\"5258964872:AAGPTJDWI2QBOqe_5jqlNqKr-fZf_xwhcEs\", chat_id=\"661328720\")\n",
    "    \n",
    "    for batch_idx, (data, labels) in enumerate(pbar):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        t = time.time()\n",
    "        embeddings = model(data)\n",
    "        t2 = time.time() - t\n",
    "        \n",
    "        loss = loss_func(embeddings, labels) / gradient_accumulation_steps\n",
    "        \n",
    "        tot_m, used_m, free_m = map(int, os.popen('free -t -m').readlines()[-1].split()[1:])\n",
    "        pbar.set_description(f\"{print_gpu_utilization()} Used RAM: {used_m} Free RAM: {free_m} Loss Train: {float(loss) * gradient_accumulation_steps} Time: {t2}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_idx % gradient_accumulation_steps == 0) or (batch_idx == train_loader_length):\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1) # ставим модель в рамки, помогает\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        \n",
    "        del data, labels, embeddings, loss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, device):\n",
    "    y_true = []\n",
    "    pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tgdm_tg(loader, token=\"5258964872:AAGPTJDWI2QBOqe_5jqlNqKr-fZf_xwhcEs\", chat_id=\"661328720\")\n",
    "    \n",
    "        for batch_idx, (data, labels) in enumerate(pbar):\n",
    "            data = data.to(device)\n",
    "            embeddings = model(data)\n",
    "            pred.extend(embeddings.argmax(-1).detach().cpu().numpy())\n",
    "            y_true.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    return y_true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true, pred):\n",
    "    print(\"matthews_corrcoef:\", matthews_corrcoef(y_true, pred))\n",
    "    print(\"accuracy_score:\", accuracy_score(y_true, pred))\n",
    "    print(\"f1_score:\", f1_score(y_true, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in bert_cls.parameters(): x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------+------------+\n",
      "|                         Modules                          | Parameters |\n",
      "+----------------------------------------------------------+------------+\n",
      "|         model.embeddings.word_embeddings.weight          |  42303744  |\n",
      "|       model.embeddings.position_embeddings.weight        |   393216   |\n",
      "|      model.embeddings.token_type_embeddings.weight       |    1536    |\n",
      "|            model.embeddings.LayerNorm.weight             |    768     |\n",
      "|             model.embeddings.LayerNorm.bias              |    768     |\n",
      "|    model.encoder.layer.0.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.0.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.0.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.0.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.0.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.0.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.0.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.0.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.0.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.0.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.0.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.0.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.0.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.0.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.0.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.0.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.1.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.1.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.1.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.1.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.1.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.1.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.1.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.1.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.1.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.1.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.1.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.1.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.1.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.1.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.1.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.1.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.2.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.2.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.2.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.2.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.2.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.2.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.2.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.2.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.2.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.2.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.2.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.2.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.2.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.2.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.2.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.2.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.3.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.3.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.3.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.3.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.3.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.3.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.3.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.3.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.3.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.3.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.3.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.3.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.3.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.3.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.3.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.3.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.4.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.4.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.4.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.4.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.4.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.4.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.4.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.4.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.4.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.4.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.4.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.4.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.4.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.4.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.4.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.4.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.5.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.5.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.5.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.5.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.5.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.5.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.5.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.5.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.5.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.5.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.5.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.5.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.5.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.5.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.5.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.5.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.6.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.6.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.6.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.6.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.6.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.6.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.6.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.6.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.6.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.6.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.6.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.6.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.6.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.6.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.6.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.6.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.7.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.7.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.7.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.7.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.7.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.7.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.7.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.7.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.7.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.7.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.7.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.7.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.7.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.7.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.7.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.7.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.8.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.8.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.8.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.8.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.8.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.8.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.8.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.8.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.8.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.8.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.8.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.8.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.8.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.8.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.8.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.8.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.9.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.9.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.9.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.9.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.9.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.9.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.9.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.9.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.9.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.9.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.9.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.9.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.9.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.9.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.9.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.9.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.10.attention.self.query.weight    |   589824   |\n",
      "|     model.encoder.layer.10.attention.self.query.bias     |    768     |\n",
      "|     model.encoder.layer.10.attention.self.key.weight     |   589824   |\n",
      "|      model.encoder.layer.10.attention.self.key.bias      |    768     |\n",
      "|    model.encoder.layer.10.attention.self.value.weight    |   589824   |\n",
      "|     model.encoder.layer.10.attention.self.value.bias     |    768     |\n",
      "|   model.encoder.layer.10.attention.output.dense.weight   |   589824   |\n",
      "|    model.encoder.layer.10.attention.output.dense.bias    |    768     |\n",
      "| model.encoder.layer.10.attention.output.LayerNorm.weight |    768     |\n",
      "|  model.encoder.layer.10.attention.output.LayerNorm.bias  |    768     |\n",
      "|     model.encoder.layer.10.intermediate.dense.weight     |  2359296   |\n",
      "|      model.encoder.layer.10.intermediate.dense.bias      |    3072    |\n",
      "|        model.encoder.layer.10.output.dense.weight        |  2359296   |\n",
      "|         model.encoder.layer.10.output.dense.bias         |    768     |\n",
      "|      model.encoder.layer.10.output.LayerNorm.weight      |    768     |\n",
      "|       model.encoder.layer.10.output.LayerNorm.bias       |    768     |\n",
      "|    model.encoder.layer.11.attention.self.query.weight    |   589824   |\n",
      "|     model.encoder.layer.11.attention.self.query.bias     |    768     |\n",
      "|     model.encoder.layer.11.attention.self.key.weight     |   589824   |\n",
      "|      model.encoder.layer.11.attention.self.key.bias      |    768     |\n",
      "|    model.encoder.layer.11.attention.self.value.weight    |   589824   |\n",
      "|     model.encoder.layer.11.attention.self.value.bias     |    768     |\n",
      "|   model.encoder.layer.11.attention.output.dense.weight   |   589824   |\n",
      "|    model.encoder.layer.11.attention.output.dense.bias    |    768     |\n",
      "| model.encoder.layer.11.attention.output.LayerNorm.weight |    768     |\n",
      "|  model.encoder.layer.11.attention.output.LayerNorm.bias  |    768     |\n",
      "|     model.encoder.layer.11.intermediate.dense.weight     |  2359296   |\n",
      "|      model.encoder.layer.11.intermediate.dense.bias      |    3072    |\n",
      "|        model.encoder.layer.11.output.dense.weight        |  2359296   |\n",
      "|         model.encoder.layer.11.output.dense.bias         |    768     |\n",
      "|      model.encoder.layer.11.output.LayerNorm.weight      |    768     |\n",
      "|       model.encoder.layer.11.output.LayerNorm.bias       |    768     |\n",
      "|                model.pooler.dense.weight                 |   589824   |\n",
      "|                 model.pooler.dense.bias                  |    768     |\n",
      "|                        fc.weight                         |  4075776   |\n",
      "|                         fc.bias                          |    5307    |\n",
      "+----------------------------------------------------------+------------+\n",
      "Total Trainable Params: 132426171\n"
     ]
    }
   ],
   "source": [
    "count_parameters(bert_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models-all-classes-lem’: File exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1af1fe67c541a0b4089bd5866a1945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd98ecbf3e6847fc8e73ef01274187c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.6014122430103136\n",
      "accuracy_score: 0.6025966694891335\n",
      "f1_score: 0.564212601147746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1effd4b4ebfe4ebeaf53eef35b5e52ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a315a587ac412fbdb24d933dbafdea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.675013354653951\n",
      "accuracy_score: 0.6759808072255151\n",
      "f1_score: 0.6514760004775421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9768d0570f534e98b7db8acb30a13fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee7966d4c9845e89228d08b241a10b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.709304161379239\n",
      "accuracy_score: 0.7101326559412927\n",
      "f1_score: 0.6924522672086093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1725cba64db4cf690b736bc748605e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/resnet-training/max_resnet_venv/lib/python3.7/site-packages/tqdm/contrib/telegram.py:38: TqdmWarning: Creation rate limit: try increasing `mininterval`.\n",
      "  self.message_id\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4548edb7c848968798cfe128006351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/resnet-training/max_resnet_venv/lib/python3.7/site-packages/tqdm/contrib/telegram.py:66: TqdmWarning: Creation rate limit: try increasing `mininterval`.\n",
      "  message_id = self.message_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.7356081092906664\n",
      "accuracy_score: 0.7363815975162292\n",
      "f1_score: 0.7237818990049587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/resnet-training/max_resnet_venv/lib/python3.7/site-packages/tqdm/contrib/telegram.py:38: TqdmWarning: Creation rate limit: try increasing `mininterval`.\n",
      "  self.message_id\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b6a5603ffd482baa776b258ba2ddc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1754 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/resnet-training/max_resnet_venv/lib/python3.7/site-packages/tqdm/contrib/telegram.py:66: TqdmWarning: Creation rate limit: try increasing `mininterval`.\n",
      "  message_id = self.message_id\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e4be49b3e14d829db4f025a9bc9402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.7378638659375621\n",
      "accuracy_score: 0.738639570985041\n",
      "f1_score: 0.7249976577283143\n"
     ]
    }
   ],
   "source": [
    "!mkdir 'models-all-classes-lem'\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    bert_cls.train()\n",
    "    \n",
    "    clear_cache()\n",
    "    train(bert_cls, loss_func, device, train_loader, optimizer,\n",
    "          epoch, gradient_accumulation_steps, scheduler)\n",
    "    PATH = f\"./models-all-classes-lem/{bert_cls.__class__.__name__}_epoch_{epoch}.pth\"\n",
    "    torch.save(bert_cls.state_dict(), PATH)\n",
    "    \n",
    "    clear_cache()\n",
    "    y_true, pred = test(bert_cls, test_loader, device)\n",
    "    metrics(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1, num_epochs + 1):\n",
    "#     PATH = f\"./models-all-classes/{bert_cls.__class__.__name__}_epoch_{epoch}.pth\"\n",
    "#     bert_cls.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "#     clear_cache()\n",
    "#     y_true, pred = test(bert_cls, test_loader, device)\n",
    "#     metrics(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected2.to_feather(\"preprocess_all_columns-lem.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "max_resnet_venv",
   "language": "python",
   "name": "max_resnet_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
