{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Л"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/exp_fold_training/temp\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 22 01:40:07 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A100 Graphics D...  On   | 00000000:B7:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    68W / 400W |      0MiB / 81252MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --fuzzy --folder https://drive.google.com/drive/folders/1XwjWRA6fcqfiTuxHhr88KoSjKISyI4sp?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.contrib.telegram import tqdm as tgdm_tg\n",
    "from prettytable import PrettyTable\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, matthews_corrcoef\n",
    "\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    return f\"GPU memory occupied: {info.used//1024**2} MB.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    model: torch.nn.Module\n",
    "    \n",
    "    Используется для подробного вывода\n",
    "    параметров модели\n",
    "    \"\"\"\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            print(name, parameter.numel())\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/LaBSE-en-ru were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/LaBSE-en-ru\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/LaBSE-en-ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contracts = pd.read_feather(\"contracts.feather\")\n",
    "goods = pd.read_feather(\"goods.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods[\"Название СТЕ\"] = goods[\"Название СТЕ\"].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization_characteristics(characteristics: str):\n",
    "    try:\n",
    "        characteristics = eval(characteristics.lower())\n",
    "        data = []\n",
    "        for characteristic in characteristics:\n",
    "            if \"value\" in characteristic:\n",
    "                if len(characteristic[\"value\"].split()) <= 3:\n",
    "                    if (\"value\" in characteristic) and (\"unit\" in characteristic):\n",
    "                        data.append(f\"{characteristic['value']} {characteristic['unit']}\")\n",
    "                    elif characteristic[\"value\"] in [\"да\", \"нет\"]:\n",
    "                        if len(characteristic[\"name\"].split()) <= 3:\n",
    "                            data.append(characteristic['name'])\n",
    "                    else:\n",
    "                        data.append(characteristic[\"value\"])\n",
    "        data = [i.strip() for i in data]\n",
    "        data = sorted(set(data))\n",
    "        return \", \".join(data)\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods[\"Характеристики\"] = goods[\"Характеристики\"].apply(standardization_characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = goods[[\"Название СТЕ\", \"Код КПГЗ\", \"Характеристики\"]].drop_duplicates()\n",
    "count_df = goods[[\"Название СТЕ\", \"Код КПГЗ\", \"Характеристики\"]].drop_duplicates().groupby(\"Код КПГЗ\").agg(\"count\").reset_index()\n",
    "classes = count_df.loc[count_df[\"Название СТЕ\"] >= 30, \"Код КПГЗ\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1420"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertCLS(nn.Module):\n",
    "    def __init__(self, model, n_classes):\n",
    "        super(BertCLS, self).__init__()\n",
    "        self.model = model\n",
    "        self.fc = nn.Linear(768, n_classes)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return self.fc(self.model(**batch).pooler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls = BertCLS(model, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected2 = selected[selected[\"Код КПГЗ\"].isin(classes)].reset_index(drop=True)\n",
    "selected2[\"Характеристики\"] = selected2[\"Характеристики\"].replace(np.nan, \"\")\n",
    "selected2[\"text\"] = selected2[\"Название СТЕ\"].str.strip().str.lower() + \" [SEP] \" + selected2[\"Характеристики\"].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "01.13.13.01.01       9262\n",
       "01.14.01.01          6906\n",
       "01.11.03.01.01.99    4646\n",
       "01.09.08.01.99       3886\n",
       "01.11.02.02.99       3829\n",
       "                     ... \n",
       "01.02.11.03.01         30\n",
       "01.13.10.02            30\n",
       "02.06.01.01.03         30\n",
       "01.13.01.01.05         30\n",
       "01.02.09.03.07         30\n",
       "Name: Код КПГЗ, Length: 1420, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected2[\"Код КПГЗ\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Название СТЕ</th>\n",
       "      <th>Код КПГЗ</th>\n",
       "      <th>Характеристики</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мяч футбольный mikasa regateador5-g</td>\n",
       "      <td>01.08.01.13.01</td>\n",
       "      <td>5 усл. ед, mikasa, regateador5-r, белый, любит...</td>\n",
       "      <td>мяч футбольный mikasa regateador5-g [SEP] 5 ус...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>мяч волейбольный gala pro-line 10 fivb</td>\n",
       "      <td>01.08.01.14.03.01</td>\n",
       "      <td>5, gala, pro-line 10 fivb, белый, профессионал...</td>\n",
       "      <td>мяч волейбольный gala pro-line 10 fivb [SEP] 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>мяч волейбольный mikasa mva380k-obl</td>\n",
       "      <td>01.08.01.14.03.01</td>\n",
       "      <td>5, mikasa, mva380k, оранжевый, синт, тренровочный</td>\n",
       "      <td>мяч волейбольный mikasa mva380k-obl [SEP] 5, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>мяч волейбольный wilson super soft play</td>\n",
       "      <td>01.08.01.14.03.01</td>\n",
       "      <td>5, super soft play, wilson, белый, любительски...</td>\n",
       "      <td>мяч волейбольный wilson super soft play [SEP] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gutrend комплект расходных материалов для fun ...</td>\n",
       "      <td>01.20.10.99</td>\n",
       "      <td>120 г, 170 мм, 220 мм, 50 мм, 6 шт, hepa фильт...</td>\n",
       "      <td>gutrend комплект расходных материалов для fun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328610</th>\n",
       "      <td>шина 23x10.50-12 107a8 starco as loader tl</td>\n",
       "      <td>01.09.08.10.05.02</td>\n",
       "      <td>10 кг, 12 дюйм, 580 мм, 8 pr, starco, бескамер...</td>\n",
       "      <td>шина 23x10.50-12 107a8 starco as loader tl [SE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328611</th>\n",
       "      <td>кнопка включения рабочего освещения для минипо...</td>\n",
       "      <td>01.09.08.03</td>\n",
       "      <td>12 в, 650, 90 г, avant, включение рабочего осв...</td>\n",
       "      <td>кнопка включения рабочего освещения для минипо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328612</th>\n",
       "      <td>обои флизелиновые под покраску nc antivandal, ...</td>\n",
       "      <td>01.11.03.11.08</td>\n",
       "      <td>106 см, 25 м, 350 г, 4 шт, 4010-16, antivandal...</td>\n",
       "      <td>обои флизелиновые под покраску nc antivandal, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328613</th>\n",
       "      <td>мусорное ведро kimberly-clark aquarius белое п...</td>\n",
       "      <td>01.20.03.03.06</td>\n",
       "      <td>2 шт, 29.00000 см, 4,76 кг, 43.00000 см, 57.00...</td>\n",
       "      <td>мусорное ведро kimberly-clark aquarius белое п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328614</th>\n",
       "      <td>весы cas db-ii 150 (е)</td>\n",
       "      <td>01.20.99.01.05.02</td>\n",
       "      <td>150 кг, 220 в, 360*460 мм, весы, наличие аккум...</td>\n",
       "      <td>весы cas db-ii 150 (е) [SEP] 150 кг, 220 в, 36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328615 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Название СТЕ           Код КПГЗ  \\\n",
       "0                     мяч футбольный mikasa regateador5-g     01.08.01.13.01   \n",
       "1                  мяч волейбольный gala pro-line 10 fivb  01.08.01.14.03.01   \n",
       "2                     мяч волейбольный mikasa mva380k-obl  01.08.01.14.03.01   \n",
       "3                 мяч волейбольный wilson super soft play  01.08.01.14.03.01   \n",
       "4       gutrend комплект расходных материалов для fun ...        01.20.10.99   \n",
       "...                                                   ...                ...   \n",
       "328610         шина 23x10.50-12 107a8 starco as loader tl  01.09.08.10.05.02   \n",
       "328611  кнопка включения рабочего освещения для минипо...        01.09.08.03   \n",
       "328612  обои флизелиновые под покраску nc antivandal, ...     01.11.03.11.08   \n",
       "328613  мусорное ведро kimberly-clark aquarius белое п...     01.20.03.03.06   \n",
       "328614                             весы cas db-ii 150 (е)  01.20.99.01.05.02   \n",
       "\n",
       "                                           Характеристики  \\\n",
       "0       5 усл. ед, mikasa, regateador5-r, белый, любит...   \n",
       "1       5, gala, pro-line 10 fivb, белый, профессионал...   \n",
       "2       5, mikasa, mva380k, оранжевый, синт, тренровочный   \n",
       "3       5, super soft play, wilson, белый, любительски...   \n",
       "4       120 г, 170 мм, 220 мм, 50 мм, 6 шт, hepa фильт...   \n",
       "...                                                   ...   \n",
       "328610  10 кг, 12 дюйм, 580 мм, 8 pr, starco, бескамер...   \n",
       "328611  12 в, 650, 90 г, avant, включение рабочего осв...   \n",
       "328612  106 см, 25 м, 350 г, 4 шт, 4010-16, antivandal...   \n",
       "328613  2 шт, 29.00000 см, 4,76 кг, 43.00000 см, 57.00...   \n",
       "328614  150 кг, 220 в, 360*460 мм, весы, наличие аккум...   \n",
       "\n",
       "                                                     text  \n",
       "0       мяч футбольный mikasa regateador5-g [SEP] 5 ус...  \n",
       "1       мяч волейбольный gala pro-line 10 fivb [SEP] 5...  \n",
       "2       мяч волейбольный mikasa mva380k-obl [SEP] 5, m...  \n",
       "3       мяч волейбольный wilson super soft play [SEP] ...  \n",
       "4       gutrend комплект расходных материалов для fun ...  \n",
       "...                                                   ...  \n",
       "328610  шина 23x10.50-12 107a8 starco as loader tl [SE...  \n",
       "328611  кнопка включения рабочего освещения для минипо...  \n",
       "328612  обои флизелиновые под покраску nc antivandal, ...  \n",
       "328613  мусорное ведро kimberly-clark aquarius белое п...  \n",
       "328614  весы cas db-ii 150 (е) [SEP] 150 кг, 220 в, 36...  \n",
       "\n",
       "[328615 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "selected2[\"target\"] = le.fit_transform(selected2[\"Код КПГЗ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(selected2[[\"text\", \"target\"]].values,\n",
    "                                   test_size=0.05,\n",
    "                                   random_state=42,\n",
    "                                   stratify=selected2[\"target\"],\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = X_train[:10000], X_test[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155.86858786117494"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected2[\"text\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, target = self.data[idx]\n",
    "        return text, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    model_input = []\n",
    "    model_target = []\n",
    "    for text, target in batch:\n",
    "        model_input.append(text)\n",
    "        model_target.append(target)\n",
    "\n",
    "    tok = tokenizer(model_input, padding=True,\n",
    "                    max_length=200, truncation=True,\n",
    "                    return_tensors='pt')\n",
    "    return tok, torch.tensor(model_target).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(dataset, shuffle, batch_size):\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=False,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "train_dataset = ClassificationDataset(X_train)\n",
    "train_loader = get_loader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_dataset = ClassificationDataset(X_test)\n",
    "test_loader = get_loader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "bert_cls = bert_cls.to(device)\n",
    "\n",
    "num_epochs = 5\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "total_steps = (len(train_loader) * num_epochs)\n",
    "optimizer = optim.AdamW(bert_cls.parameters(), lr=2e-4)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=2e-4,\n",
    "                                          total_steps=total_steps,\n",
    "                                          div_factor=25,\n",
    "                                          pct_start=0.1)\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, device, train_loader, optimizer, epoch, gradient_accumulation_steps, scheduler):\n",
    "    model.train()\n",
    "    train_loader_length = len(train_loader) - 1 # хотим знать когда эпоха закончится\n",
    "    pbar = tgdm_tg(train_loader, token=\"5258964872:AAGPTJDWI2QBOqe_5jqlNqKr-fZf_xwhcEs\", chat_id=\"661328720\")\n",
    "    \n",
    "    for batch_idx, (data, labels) in enumerate(pbar):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        \n",
    "        t = time.time()\n",
    "        embeddings = model(data)\n",
    "        t2 = time.time() - t\n",
    "        \n",
    "        loss = loss_func(embeddings, labels) / gradient_accumulation_steps\n",
    "        \n",
    "        tot_m, used_m, free_m = map(int, os.popen('free -t -m').readlines()[-1].split()[1:])\n",
    "        pbar.set_description(f\"{print_gpu_utilization()} Used RAM: {used_m} Free RAM: {free_m} Loss Train: {float(loss) * gradient_accumulation_steps} Time: {t2}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_idx % gradient_accumulation_steps == 0) or (batch_idx == train_loader_length):\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1) # ставим модель в рамки, помогает\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "        \n",
    "        del data, labels, embeddings, loss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, device):\n",
    "    y_true = []\n",
    "    pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tgdm_tg(loader, token=\"5258964872:AAGPTJDWI2QBOqe_5jqlNqKr-fZf_xwhcEs\", chat_id=\"661328720\")\n",
    "    \n",
    "        for batch_idx, (data, labels) in enumerate(pbar):\n",
    "            data = data.to(device)\n",
    "            embeddings = model(data)\n",
    "            pred.extend(embeddings.argmax(-1).detach().cpu().numpy())\n",
    "            y_true.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    return y_true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true, pred):\n",
    "    print(\"matthews_corrcoef:\", matthews_corrcoef(y_true, pred))\n",
    "    print(\"accuracy_score:\", accuracy_score(y_true, pred))\n",
    "    print(\"f1_score:\", f1_score(y_true, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in bert_cls.parameters(): x.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------+------------+\n",
      "|                         Modules                          | Parameters |\n",
      "+----------------------------------------------------------+------------+\n",
      "|         model.embeddings.word_embeddings.weight          |  42303744  |\n",
      "|       model.embeddings.position_embeddings.weight        |   393216   |\n",
      "|      model.embeddings.token_type_embeddings.weight       |    1536    |\n",
      "|            model.embeddings.LayerNorm.weight             |    768     |\n",
      "|             model.embeddings.LayerNorm.bias              |    768     |\n",
      "|    model.encoder.layer.0.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.0.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.0.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.0.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.0.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.0.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.0.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.0.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.0.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.0.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.0.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.0.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.0.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.0.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.0.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.0.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.1.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.1.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.1.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.1.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.1.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.1.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.1.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.1.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.1.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.1.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.1.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.1.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.1.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.1.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.1.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.1.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.2.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.2.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.2.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.2.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.2.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.2.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.2.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.2.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.2.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.2.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.2.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.2.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.2.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.2.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.2.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.2.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.3.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.3.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.3.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.3.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.3.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.3.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.3.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.3.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.3.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.3.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.3.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.3.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.3.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.3.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.3.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.3.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.4.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.4.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.4.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.4.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.4.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.4.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.4.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.4.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.4.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.4.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.4.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.4.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.4.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.4.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.4.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.4.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.5.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.5.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.5.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.5.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.5.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.5.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.5.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.5.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.5.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.5.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.5.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.5.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.5.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.5.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.5.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.5.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.6.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.6.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.6.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.6.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.6.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.6.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.6.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.6.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.6.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.6.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.6.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.6.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.6.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.6.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.6.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.6.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.7.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.7.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.7.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.7.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.7.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.7.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.7.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.7.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.7.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.7.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.7.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.7.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.7.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.7.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.7.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.7.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.8.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.8.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.8.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.8.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.8.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.8.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.8.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.8.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.8.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.8.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.8.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.8.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.8.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.8.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.8.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.8.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.9.attention.self.query.weight     |   589824   |\n",
      "|     model.encoder.layer.9.attention.self.query.bias      |    768     |\n",
      "|     model.encoder.layer.9.attention.self.key.weight      |   589824   |\n",
      "|      model.encoder.layer.9.attention.self.key.bias       |    768     |\n",
      "|    model.encoder.layer.9.attention.self.value.weight     |   589824   |\n",
      "|     model.encoder.layer.9.attention.self.value.bias      |    768     |\n",
      "|   model.encoder.layer.9.attention.output.dense.weight    |   589824   |\n",
      "|    model.encoder.layer.9.attention.output.dense.bias     |    768     |\n",
      "| model.encoder.layer.9.attention.output.LayerNorm.weight  |    768     |\n",
      "|  model.encoder.layer.9.attention.output.LayerNorm.bias   |    768     |\n",
      "|     model.encoder.layer.9.intermediate.dense.weight      |  2359296   |\n",
      "|      model.encoder.layer.9.intermediate.dense.bias       |    3072    |\n",
      "|        model.encoder.layer.9.output.dense.weight         |  2359296   |\n",
      "|         model.encoder.layer.9.output.dense.bias          |    768     |\n",
      "|      model.encoder.layer.9.output.LayerNorm.weight       |    768     |\n",
      "|       model.encoder.layer.9.output.LayerNorm.bias        |    768     |\n",
      "|    model.encoder.layer.10.attention.self.query.weight    |   589824   |\n",
      "|     model.encoder.layer.10.attention.self.query.bias     |    768     |\n",
      "|     model.encoder.layer.10.attention.self.key.weight     |   589824   |\n",
      "|      model.encoder.layer.10.attention.self.key.bias      |    768     |\n",
      "|    model.encoder.layer.10.attention.self.value.weight    |   589824   |\n",
      "|     model.encoder.layer.10.attention.self.value.bias     |    768     |\n",
      "|   model.encoder.layer.10.attention.output.dense.weight   |   589824   |\n",
      "|    model.encoder.layer.10.attention.output.dense.bias    |    768     |\n",
      "| model.encoder.layer.10.attention.output.LayerNorm.weight |    768     |\n",
      "|  model.encoder.layer.10.attention.output.LayerNorm.bias  |    768     |\n",
      "|     model.encoder.layer.10.intermediate.dense.weight     |  2359296   |\n",
      "|      model.encoder.layer.10.intermediate.dense.bias      |    3072    |\n",
      "|        model.encoder.layer.10.output.dense.weight        |  2359296   |\n",
      "|         model.encoder.layer.10.output.dense.bias         |    768     |\n",
      "|      model.encoder.layer.10.output.LayerNorm.weight      |    768     |\n",
      "|       model.encoder.layer.10.output.LayerNorm.bias       |    768     |\n",
      "|    model.encoder.layer.11.attention.self.query.weight    |   589824   |\n",
      "|     model.encoder.layer.11.attention.self.query.bias     |    768     |\n",
      "|     model.encoder.layer.11.attention.self.key.weight     |   589824   |\n",
      "|      model.encoder.layer.11.attention.self.key.bias      |    768     |\n",
      "|    model.encoder.layer.11.attention.self.value.weight    |   589824   |\n",
      "|     model.encoder.layer.11.attention.self.value.bias     |    768     |\n",
      "|   model.encoder.layer.11.attention.output.dense.weight   |   589824   |\n",
      "|    model.encoder.layer.11.attention.output.dense.bias    |    768     |\n",
      "| model.encoder.layer.11.attention.output.LayerNorm.weight |    768     |\n",
      "|  model.encoder.layer.11.attention.output.LayerNorm.bias  |    768     |\n",
      "|     model.encoder.layer.11.intermediate.dense.weight     |  2359296   |\n",
      "|      model.encoder.layer.11.intermediate.dense.bias      |    3072    |\n",
      "|        model.encoder.layer.11.output.dense.weight        |  2359296   |\n",
      "|         model.encoder.layer.11.output.dense.bias         |    768     |\n",
      "|      model.encoder.layer.11.output.LayerNorm.weight      |    768     |\n",
      "|       model.encoder.layer.11.output.LayerNorm.bias       |    768     |\n",
      "|                model.pooler.dense.weight                 |   589824   |\n",
      "|                 model.pooler.dense.bias                  |    768     |\n",
      "|                        fc.weight                         |  1090560   |\n",
      "|                         fc.bias                          |    1420    |\n",
      "+----------------------------------------------------------+------------+\n",
      "Total Trainable Params: 129437068\n"
     ]
    }
   ],
   "source": [
    "count_parameters(bert_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1821cd37a1486cb5a02d63fac30663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/resnet-training/max_resnet_venv/lib/python3.7/site-packages/tqdm/contrib/telegram.py:38: TqdmWarning: Creation rate limit: try increasing `mininterval`.\n",
      "  self.message_id\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8203f0c8198b43bfab176c867b3f8992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/resnet-training/max_resnet_venv/lib/python3.7/site-packages/tqdm/contrib/telegram.py:66: TqdmWarning: Creation rate limit: try increasing `mininterval`.\n",
      "  message_id = self.message_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.8244674203353249\n",
      "accuracy_score: 0.8250867263100238\n",
      "f1_score: 0.8100397013298607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/resnet-training/max_resnet_venv/lib/python3.7/site-packages/tqdm/contrib/telegram.py:38: TqdmWarning: Creation rate limit: try increasing `mininterval`.\n",
      "  self.message_id\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5daaba7d91624a429dea9a1dbc9d5230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/minerals/gerasimov/resnet-training/max_resnet_venv/lib/python3.7/site-packages/tqdm/contrib/telegram.py:66: TqdmWarning: Creation rate limit: try increasing `mininterval`.\n",
      "  message_id = self.message_id\n"
     ]
    }
   ],
   "source": [
    "!mkdir models\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    bert_cls.train()\n",
    "    \n",
    "    clear_cache()\n",
    "    train(bert_cls, loss_func, device, train_loader, optimizer,\n",
    "          epoch, gradient_accumulation_steps, scheduler)\n",
    "    PATH = f\"./models/{bert_cls.__class__.__name__}_epoch_{epoch}.pth\"\n",
    "    torch.save(bert_cls.state_dict(), PATH)\n",
    "    \n",
    "    clear_cache()\n",
    "    y_true, pred = test(bert_cls, test_loader, device)\n",
    "    metrics(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35060494ef04cdc876469a450197a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.8244674203353249\n",
      "accuracy_score: 0.8250867263100238\n",
      "f1_score: 0.8100397013298607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a0f8a6d4f84efb9e7534897016665c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.8728934869441873\n",
      "accuracy_score: 0.8733491570811271\n",
      "f1_score: 0.8675170804020862\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34b120839d045c396a026378d6d4362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.8988493908080971\n",
      "accuracy_score: 0.8992148986671535\n",
      "f1_score: 0.8957247643818462\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9431c86253346cab6ef608851dbe1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.9139343657081539\n",
      "accuracy_score: 0.9142474590712677\n",
      "f1_score: 0.9119584445917452\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85690f335d4b4dec9f5932686e786e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matthews_corrcoef: 0.9183322911798375\n",
      "accuracy_score: 0.9186294199987828\n",
      "f1_score: 0.9163812810262328\n"
     ]
    }
   ],
   "source": [
    "!mkdir models\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    PATH = f\"./models/{bert_cls.__class__.__name__}_epoch_{epoch}.pth\"\n",
    "    bert_cls.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    clear_cache()\n",
    "    y_true, pred = test(bert_cls, test_loader, device)\n",
    "    metrics(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "max_resnet_venv",
   "language": "python",
   "name": "max_resnet_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
